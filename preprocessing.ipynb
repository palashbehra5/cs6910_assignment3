{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from unicodedata import category, normalize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "51200\n",
      "4096\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "directories = os.listdir(\"aksharantar_sampled/hin/\")\n",
    "train_data, val_data, test_data = [],[],[]\n",
    "\n",
    "for i in open(\"aksharantar_sampled/hin/\"+directories[0], encoding='utf-8'):\n",
    "    test_data.append([i.split(\",\")[0],i.split(\",\")[1][:-1]])\n",
    "\n",
    "for i in open(\"aksharantar_sampled/hin/\"+directories[1], encoding='utf-8'):\n",
    "    train_data.append([i.split(\",\")[0],i.split(\",\")[1][:-1]])\n",
    "\n",
    "for i in open(\"aksharantar_sampled/hin/\"+directories[2], encoding='utf-8'):\n",
    "    val_data.append([i.split(\",\")[0],i.split(\",\")[1][:-1]])\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "\n",
    "def hindi_chars(hindi_word):\n",
    "\n",
    "    return [c for c in normalize('NFD', hindi_word) if category(c) != 'Mn']\n",
    "\n",
    "def english_chars(english_word):\n",
    "\n",
    "    return [c for c in english_word]\n",
    "\n",
    "def one_hot(x, n):\n",
    "\n",
    "    encoding = np.zeros(n)\n",
    "    encoding[x] = 1\n",
    "    return encoding\n",
    "\n",
    "def generate_char_to_idx():\n",
    "    \n",
    "    en_start, en_end = 0x0061, 0x007A # ASCII characters (lowercase only)\n",
    "    hi_start, hi_end = 0x0900, 0x0965 # Devanagari characters\n",
    "\n",
    "    char_to_idx = {}\n",
    "\n",
    "    for i, char in enumerate(range(en_start, en_end+1)):\n",
    "        char_to_idx[chr(char)] = len(char_to_idx)\n",
    "\n",
    "    for i, char in enumerate(range(hi_start, hi_end+1)):\n",
    "        char_to_idx[chr(char)] = len(char_to_idx)\n",
    "\n",
    "    return char_to_idx\n",
    "\n",
    "char_to_idx = generate_char_to_idx()\n",
    "char_to_idx['/start'] = len(char_to_idx)\n",
    "char_to_idx['/end'] = len(char_to_idx)\n",
    "char_to_idx['/pad']  = len(char_to_idx)\n",
    "\n",
    "def word_to_idx(data):\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for eng_word, hin_word in data:\n",
    "\n",
    "        eng_sequence = [char_to_idx[char] for char in eng_word]\n",
    "        hin_sequence = [char_to_idx[char] for char in hin_word]\n",
    "\n",
    "        eng_sequence.insert(0,char_to_idx['/start'])\n",
    "        hin_sequence.insert(0,char_to_idx['/start'])\n",
    "\n",
    "        eng_sequence.append(char_to_idx['/end'])\n",
    "        hin_sequence.append(char_to_idx['/end'])\n",
    "\n",
    "        data[idx][0] = eng_sequence\n",
    "        data[idx][1] = hin_sequence\n",
    "\n",
    "        idx+=1\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = word_to_idx(train_data)\n",
    "test_data = word_to_idx(test_data)\n",
    "val_data = word_to_idx(val_data)\n",
    "\n",
    "print(len(char_to_idx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 0\n",
    "\n",
    "def set_max_seq(data):\n",
    "\n",
    "    max_seq_length = 0\n",
    "\n",
    "    for seq_x, seq_y in data:\n",
    "\n",
    "        if(len(seq_x) > max_seq_length) : max_seq_length = len(seq_x)\n",
    "        if(len(seq_y) > max_seq_length) : max_seq_length = len(seq_y)\n",
    "\n",
    "    return max_seq_length\n",
    "\n",
    "def pad(data, max_seq_length):\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for seq_x, seq_y in data:\n",
    "\n",
    "        while(len(seq_x) < max_seq_length):\n",
    "\n",
    "            seq_x.insert(-1, char_to_idx['/pad'])\n",
    "\n",
    "        while(len(seq_y) < max_seq_length):\n",
    "\n",
    "            seq_y.insert(-1, char_to_idx['/pad'])\n",
    "\n",
    "        data[idx][0] = seq_x\n",
    "        data[idx][1] = seq_y\n",
    "\n",
    "        idx+=1\n",
    "\n",
    "    return data\n",
    "\n",
    "max_seq_length = max(max_seq_length , set_max_seq(train_data))\n",
    "max_seq_length = max(max_seq_length , set_max_seq(test_data))\n",
    "max_seq_length = max(max_seq_length , set_max_seq(val_data))\n",
    "\n",
    "print(max_seq_length)\n",
    "\n",
    "train_data = np.array(pad(train_data, max_seq_length))\n",
    "test_data = np.array(pad(test_data, max_seq_length))\n",
    "val_data = np.array(pad(val_data, max_seq_length))\n",
    "\n",
    "x_train,y_train = train_data[:,0],train_data[:,1]\n",
    "x_val,y_val = val_data[:,0],val_data[:,1]\n",
    "x_test,y_test = test_data[:,0],test_data[:,1]\n",
    "\n",
    "np.savetxt(\"akshar_sequences/x_train.csv\", np.array(x_train), delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"akshar_sequences/x_test.csv\", np.array(x_test), delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"akshar_sequences/x_val.csv\", np.array(x_val), delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"akshar_sequences/y_train.csv\", np.array(y_train), delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"akshar_sequences/y_test.csv\", np.array(y_test), delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"akshar_sequences/y_val.csv\", np.array(y_val), delimiter=\",\", fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
